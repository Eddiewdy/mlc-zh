{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习 1：广播加法\n",
    "\n",
    "请编写一个 TensorIR 函数，将两个数组以广播的方式相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(4, 0, -1).reshape(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  4,  4],\n",
       "       [ 8,  8,  8,  8],\n",
       "       [12, 12, 12, 12],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy version\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost of transformed mod_transformed 2.92e-08 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:24:16] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n"
     ]
    }
   ],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4,4),\"int64\"],\n",
    "          B: T.Buffer[(4),\"int64\"],\n",
    "          C: T.Buffer[(4,4),\"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
    "    for i, j in T.grid(4, 4):\n",
    "        with T.block(\"C\"):\n",
    "            vi=T.axis.spatial(4, i)\n",
    "            vj=T.axis.spatial(4, j)\n",
    "            C[vi, vj] = A[vi, vj] + B[vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=\"int64\"))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "f_timer = rt_lib.time_evaluator(\"add\", tvm.cpu())\n",
    "print(\"Time cost of transformed mod_transformed %g sec\" % f_timer(a_tvm, b_tvm, c_tvm).mean)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习 2：二维卷积\n",
    "\n",
    "然后，让我们尝试做一些具有挑战性的事情：二维卷积。这是图像处理中的常见操作。\n",
    "\n",
    "这是使用 NCHW 布局的卷积的数学定义：\n",
    "$$Conv[b, k, i, j] =\n",
    "    \\sum_{di, dj, q} A[b, q, strides * i + di, strides * j + dj] * W[k, q, di, dj],$$\n",
    "其中，`A` 是输入张量，`W` 是权重张量，`b` 是批次索引，`k` 是输出通道，`i` 和 `j` 是图像高度和宽度的索引，`di` 和 `dj` 是权重的索引，`q` 是输入通道，`strides` 是过滤器窗口的步幅。\n",
    "\n",
    "在练习中，我们选择了一个小而简单的情况，即 `stride=1, padding=0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
    "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 474,  510,  546,  582,  618,  654],\n",
       "         [ 762,  798,  834,  870,  906,  942],\n",
       "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
       "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
       "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
       "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
       "\n",
       "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
       "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
       "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
       "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
       "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
       "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch version\n",
    "import torch\n",
    "data_torch = torch.Tensor(data)\n",
    "weight_torch = torch.Tensor(weight)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
    "conv_torch = conv_torch.numpy().astype(np.int64)\n",
    "conv_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      " --> /var/folders/bg/vzcr5j8d297c300rzc9gyb2w0000gn/T/ipykernel_16879/3303365678.py:6:5\n",
      "   |  \n",
      " 6 |      for b, k, i, j, q, di, dj in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
      "   |      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "ename": "DiagnosticError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) 9   python3.10                          0x00000001007586c4 _PyObject_MakeTpCall + 136\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x0000000101422178 PyCFuncPtr_call + 220\n  [bt] (6) 7   _ctypes.cpython-310-darwin.so       0x000000010142842c _ctypes_callproc + 936\n  [bt] (5) 6   libffi.8.dylib                      0x0000000101445790 ffi_call_int + 1256\n  [bt] (4) 5   libffi.8.dylib                      0x000000010144804c ffi_call_SYSV + 76\n  [bt] (3) 4   libtvm.dylib                        0x000000013cdc5af4 TVMFuncCall + 60\n  [bt] (2) 3   libtvm.dylib                        0x000000013b31b468 tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<void tvm::runtime::TypedPackedFunc<void (tvm::DiagnosticContext)>::AssignTypedLambda<tvm::$_8>(tvm::$_8, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >)::'lambda'(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) + 776\n  [bt] (1) 2   libtvm.dylib                        0x000000013b311368 tvm::DiagnosticContext::Render() + 468\n  [bt] (0) 1   libtvm.dylib                        0x000000013b006e28 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84\n  File \"/Users/yd/Documents/tvm/src/ir/diagnostic.cc\", line 105\nDiagnosticError: one or more error diagnostics were emitted, please check diagnostic render for output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:194\u001b[0m, in \u001b[0;36m_dispatch_wrapper.<locals>._wrapper\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, node)\n\u001b[1;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m DiagnosticError:\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/tir/parser.py:176\u001b[0m, in \u001b[0;36mvisit_for\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m for_frame \u001b[39mas\u001b[39;00m iters:\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_assign(target\u001b[39m=\u001b[39;49mnode\u001b[39m.\u001b[39;49mtarget, source\u001b[39m=\u001b[39;49miters, bind_value\u001b[39m=\u001b[39;49mbind_for_value)\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_body(node\u001b[39m.\u001b[39mbody)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:368\u001b[0m, in \u001b[0;36mParser.eval_assign\u001b[0;34m(self, target, source, bind_value, allow_shadowing)\u001b[0m\n\u001b[1;32m    367\u001b[0m     var \u001b[39m=\u001b[39m bind_value(\u001b[39mself\u001b[39m, target, k, v)\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_table\u001b[39m.\u001b[39;49madd(k, var, allow_shadowing)\n\u001b[1;32m    369\u001b[0m \u001b[39mreturn\u001b[39;00m var_values\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:153\u001b[0m, in \u001b[0;36mVarTable.add\u001b[0;34m(self, var, value, allow_shadowing)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m# Skip if the key and value are equal to those in the var_table\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname2value[var] \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname2value[var][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m value:\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDiagnosticError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m@tvm\u001b[39;49m\u001b[39m.\u001b[39;49mscript\u001b[39m.\u001b[39;49mir_module\n\u001b[0;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mMyConv\u001b[39;49;00m:\n\u001b[1;32m      3\u001b[0m   \u001b[39m@T\u001b[39;49m\u001b[39m.\u001b[39;49mprim_func\n\u001b[1;32m      4\u001b[0m   \u001b[39mdef\u001b[39;49;00m \u001b[39mconv\u001b[39;49m(A: T\u001b[39m.\u001b[39;49mBuffer[(N, CI, H, W), \u001b[39m\"\u001b[39;49m\u001b[39mint64\u001b[39;49m\u001b[39m\"\u001b[39;49m], B: T\u001b[39m.\u001b[39;49mBuffer[(CO, CI, K, K), \u001b[39m\"\u001b[39;49m\u001b[39mint64\u001b[39;49m\u001b[39m\"\u001b[39;49m], C: T\u001b[39m.\u001b[39;49mBuffer[(N, CO, OUT_H, OUT_W), \u001b[39m\"\u001b[39;49m\u001b[39mint64\u001b[39;49m\u001b[39m\"\u001b[39;49m]):\n\u001b[1;32m      5\u001b[0m     T\u001b[39m.\u001b[39;49mfunc_attr({\u001b[39m\"\u001b[39;49m\u001b[39mglobal_symbol\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mconv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtir.noalias\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m})\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/ir/entry.py:43\u001b[0m, in \u001b[0;36mir_module\u001b[0;34m(mod)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(mod):\n\u001b[1;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpect a class, but got: \u001b[39m\u001b[39m{\u001b[39;00mmod\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[39mreturn\u001b[39;00m parse(mod, utils\u001b[39m.\u001b[39;49minspect_class_capture(mod))\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/entry.py:57\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(program, extra_vars)\u001b[0m\n\u001b[1;32m     55\u001b[0m parser \u001b[39m=\u001b[39m Parser(source)\n\u001b[1;32m     56\u001b[0m \u001b[39mwith\u001b[39;00m IRBuilder() \u001b[39mas\u001b[39;00m builder:\n\u001b[0;32m---> 57\u001b[0m     parser\u001b[39m.\u001b[39;49mparse(extra_vars\u001b[39m=\u001b[39;49mextra_vars)\n\u001b[1;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m builder\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:256\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self, extra_vars)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_table\u001b[39m.\u001b[39madd(k, v)\n\u001b[1;32m    255\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiag\u001b[39m.\u001b[39msource\u001b[39m.\u001b[39mas_ast()\n\u001b[0;32m--> 256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:418\u001b[0m, in \u001b[0;36mParser.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVisitor of AST node is not implemented: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     func(node)\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    420\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/doc.py:257\u001b[0m, in \u001b[0;36mNodeVisitor.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (doc\u001b[39m.\u001b[39mAST, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:406\u001b[0m, in \u001b[0;36mParser.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    405\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m node:\n\u001b[0;32m--> 406\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(item)\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, doc\u001b[39m.\u001b[39mAST):\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:418\u001b[0m, in \u001b[0;36mParser.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVisitor of AST node is not implemented: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     func(node)\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    420\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:497\u001b[0m, in \u001b[0;36mParser.visit_ClassDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(node, \u001b[39m\"\u001b[39m\u001b[39mThe parser does not understand the decorator\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 497\u001b[0m _dispatch_wrapper(func)(\u001b[39mself\u001b[39;49m, node)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:194\u001b[0m, in \u001b[0;36m_dispatch_wrapper.<locals>._wrapper\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapper\u001b[39m(\u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mParser\u001b[39m\u001b[39m\"\u001b[39m, node: doc\u001b[39m.\u001b[39mAST) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, node)\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    196\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/ir/parser.py:38\u001b[0m, in \u001b[0;36m_visit_class_def\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mwith\u001b[39;00m I\u001b[39m.\u001b[39mir_module():\n\u001b[1;32m     37\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_dispatch_token(\u001b[39m\"\u001b[39m\u001b[39mir\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_body(node\u001b[39m.\u001b[39;49mbody)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:439\u001b[0m, in \u001b[0;36mParser.visit_body\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"The general body visiting method.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m    The visiting result.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m node:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(stmt)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:418\u001b[0m, in \u001b[0;36mParser.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVisitor of AST node is not implemented: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     func(node)\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    420\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:479\u001b[0m, in \u001b[0;36mParser.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(node, \u001b[39m\"\u001b[39m\u001b[39mThe parser does not understand the decorator\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 479\u001b[0m _dispatch_wrapper(func)(\u001b[39mself\u001b[39;49m, node)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:194\u001b[0m, in \u001b[0;36m_dispatch_wrapper.<locals>._wrapper\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapper\u001b[39m(\u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mParser\u001b[39m\u001b[39m\"\u001b[39m, node: doc\u001b[39m.\u001b[39mAST) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, node)\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    196\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/tir/parser.py:351\u001b[0m, in \u001b[0;36mvisit_function_def\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_dispatch_token(\u001b[39m\"\u001b[39m\u001b[39mtir\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    350\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39margs)\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_body(node\u001b[39m.\u001b[39;49mbody)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:439\u001b[0m, in \u001b[0;36mParser.visit_body\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"The general body visiting method.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m    The visiting result.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m node:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(stmt)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:418\u001b[0m, in \u001b[0;36mParser.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mVisitor of AST node is not implemented: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     func(node)\n\u001b[1;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m DiagnosticError:\n\u001b[1;32m    420\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:527\u001b[0m, in \u001b[0;36mParser.visit_For\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_For\u001b[39m(\u001b[39mself\u001b[39m, node: doc\u001b[39m.\u001b[39mFor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[39m\"\"\"The general for visiting method.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m        The visiting result.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m     \u001b[39mreturn\u001b[39;00m _dispatch(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mFor\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, node)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:198\u001b[0m, in \u001b[0;36m_dispatch_wrapper.<locals>._wrapper\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except,invalid-name\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreport_error(node, e)\n\u001b[1;32m    199\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/parser.py:389\u001b[0m, in \u001b[0;36mParser.report_error\u001b[0;34m(self, node, err)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[0;32m--> 389\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiag\u001b[39m.\u001b[39;49merror(node, msg)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/script/parser/core/diagnostics.py:256\u001b[0m, in \u001b[0;36mDiagnostics.error\u001b[0;34m(self, node, message)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m\"\"\"Emit a diagnostic error.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \n\u001b[1;32m    247\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m    The diagnostic message.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_emit(node, message, diagnostics\u001b[39m.\u001b[39mDiagnosticLevel\u001b[39m.\u001b[39mERROR)\n\u001b[0;32m--> 256\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/ir/diagnostics/__init__.py:119\u001b[0m, in \u001b[0;36mDiagnosticContext.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[39m\"\"\"Render the current context using its renderer member.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     _ffi_api\u001b[39m.\u001b[39;49mDiagnosticContextRender(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/tvm/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mDiagnosticError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) 9   python3.10                          0x00000001007586c4 _PyObject_MakeTpCall + 136\n  [bt] (7) 8   _ctypes.cpython-310-darwin.so       0x0000000101422178 PyCFuncPtr_call + 220\n  [bt] (6) 7   _ctypes.cpython-310-darwin.so       0x000000010142842c _ctypes_callproc + 936\n  [bt] (5) 6   libffi.8.dylib                      0x0000000101445790 ffi_call_int + 1256\n  [bt] (4) 5   libffi.8.dylib                      0x000000010144804c ffi_call_SYSV + 76\n  [bt] (3) 4   libtvm.dylib                        0x000000013cdc5af4 TVMFuncCall + 60\n  [bt] (2) 3   libtvm.dylib                        0x000000013b31b468 tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<void tvm::runtime::TypedPackedFunc<void (tvm::DiagnosticContext)>::AssignTypedLambda<tvm::$_8>(tvm::$_8, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >)::'lambda'(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) + 776\n  [bt] (1) 2   libtvm.dylib                        0x000000013b311368 tvm::DiagnosticContext::Render() + 468\n  [bt] (0) 1   libtvm.dylib                        0x000000013b006e28 tvm::runtime::detail::LogFatal::Entry::Finalize() + 84\n  File \"/Users/yd/Documents/tvm/src/ir/diagnostic.cc\", line 105\nDiagnosticError: one or more error diagnostics were emitted, please check diagnostic render for output."
     ]
    }
   ],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "  @T.prim_func\n",
    "  def conv(A: T.Buffer[(N, CI, H, W), \"int64\"], B: T.Buffer[(CO, CI, K, K), \"int64\"], C: T.Buffer[(N, CO, OUT_H, OUT_W), \"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
    "    for b, k, i, j, q, di, dj in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
    "      with T.block(\"C\"):\n",
    "        vb=T.axis.spatial(N, b)\n",
    "        vk=T.axis.spatial(CO, k)\n",
    "        vi=T.axis.spatial(OUT_H, i)\n",
    "        vj=T.axis.spatial(OUT_W, j)\n",
    "        vq=T.axis.reduce(CI, q)\n",
    "        vdi=T.axis.reduce(K, di)\n",
    "        vdj=T.axis.reduce(K, dj)\n",
    "        \n",
    "        # hbsun: need init first\n",
    "        with T.init():\n",
    "          C[vb, vk, vi, vj] = T.int64(0)\n",
    "        C[vb, vk, vi, vj] += A[vb, vq, vi+vdi, vj+vdj] * B[vk, vq, vdi, vdj]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二节：如何变换 TensorIR\n",
    "\n",
    "在讲座中，我们了解到 TensorIR 不仅是一种编程语言，而且还是一种程序变换的抽象。在本节中，让我们尝试变换程序。我们在采用了 `bmm_relu` (`batched_matmul_relu`)，这是一种常见于 Transformer 等模型中的操作变体。\n",
    "\n",
    "#### 并行化、向量化与循环展开\n",
    "\n",
    "首先，我们介绍一些新的原语：`parallel`、`vectorize` 和 `unroll`。这三个原语被应用于循环上，指示循环应当如何执行。这是示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># from tvm.script import tir as T</span>\n",
       "<span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;add&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">i_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
       "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
       "                        <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">i_0</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">i_1</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} from tvm.script import tir as T}\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{add}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{add}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{k}{for} \\PY{n}{i\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{parallel}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{for} \\PY{n}{i\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{unroll}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{k}{for} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                        \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{i\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{2} \\PY{o}{+} \\PY{n}{i\\PYZus{}1}\\PY{p}{)}\n",
       "                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{j}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# from tvm.script import tir as T\n",
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def add(A: T.Buffer[(4, 4), \"int64\"], B: T.Buffer[(4, 4), \"int64\"], C: T.Buffer[(4, 4), \"int64\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"global_symbol\": \"add\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        for i_0 in T.parallel(2):\n",
       "            for i_1 in T.unroll(2):\n",
       "                for j in T.vectorized(4):\n",
       "                    with T.block(\"C\"):\n",
       "                        vi = T.axis.spatial(4, i_0 * 2 + i_1)\n",
       "                        vj = T.axis.spatial(4, j)\n",
       "                        T.reads(A[vi, vj], B[vi, vj])\n",
       "                        T.writes(C[vi, vj])\n",
       "                        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
       "    "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
    "          B: T.Buffer[(4, 4), \"int64\"],\n",
    "          C: T.Buffer[(4, 4), \"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\"})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
    "\n",
    "sch = tvm.tir.Schedule(MyAdd)\n",
    "block = sch.get_block(\"C\", func_name=\"add\")\n",
    "i, j = sch.get_loops(block)\n",
    "i0, i1 = sch.split(i, factors=[None, 2])\n",
    "sch.parallel(i0)\n",
    "sch.unroll(i1)\n",
    "sch.vectorize(j)\n",
    "IPython.display.Code(sch.mod.script(), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
    "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                for k in range(128):\n",
    "                    if k == 0:\n",
    "                        Y[n, i, j] = 0\n",
    "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                C[n, i, j] = max(Y[n, i, j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
      "        for n, i, j, k in T.grid(16, 128, 128, 128):\n",
      "            with T.block(\"Y\"):\n",
      "                vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
      "                T.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
      "                T.writes(Y[vn, vi, vj])\n",
      "                with T.init():\n",
      "                    Y[vn, vi, vj] = T.float32(0)\n",
      "                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
      "        for n, i, j in T.grid(16, 128, 128):\n",
      "            with T.block(\"C\"):\n",
      "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
      "                T.reads(Y[vn, vi, vj])\n",
      "                T.writes(C[vn, vi, vj])\n",
      "                C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @tvm.script.ir_module\n",
    "# class MyBmmRelu:\n",
    "#   @T.prim_func\n",
    "#   def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
    "#     T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "#     Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "#     for i, j, k, n in T.grid(128, 128, 128, 16):\n",
    "#       with T.block(\"Y\"):\n",
    "#         vi, vj, vk, vn = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
    "#         with T.init():\n",
    "#           Y[vn, vi, vj] = T.float32(0)\n",
    "#         Y[vn, vi, vj] += A[vn, vi, vk] * B[vn, vk, vj]\n",
    "#     for i, j, n in T.grid(128, 128, 16):\n",
    "#       with T.block(\"C\"):\n",
    "#         vi, vj, vn = T.axis.remap(\"SSR\", [n, i, j])\n",
    "#         Y[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
    "@tvm.script.ir_module\n",
    "class MyBmmRelu:\n",
    "  @T.prim_func\n",
    "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"],\n",
    "               B: T.Buffer[(16, 128, 128), \"float32\"],\n",
    "               C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
    "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "    Y = T.alloc_buffer((16, 128, 128), dtype=\"float32\")\n",
    "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
    "        with T.block(\"Y\"):\n",
    "            vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
    "            with T.init():\n",
    "                Y[vn, vi, vj] = T.float32(0)\n",
    "            Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
    "\n",
    "    for n, i, j in T.grid(16, 128, 128):\n",
    "                with T.block(\"C\"):\n",
    "                    vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
    "                    C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
    "\n",
    "\n",
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "print(sch.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class TargetModule:\n",
    "    @T.prim_func\n",
    "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
    "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "        for i0 in T.parallel(16):\n",
    "            for i1, i2_0 in T.grid(128, 16):\n",
    "                for ax0_init in T.vectorized(8):\n",
    "                    with T.block(\"Y_init\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
    "                        Y[n, i, j] = T.float32(0)\n",
    "                for ax1_0 in T.serial(32):\n",
    "                    for ax1_1 in T.unroll(4):\n",
    "                        for ax0 in T.serial(8):\n",
    "                            with T.block(\"Y_update\"):\n",
    "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
    "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
    "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "                for i2_1 in T.vectorized(8):\n",
    "                    with T.block(\"C\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
    "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
      "        for n in T.parallel(16):\n",
      "            for i, j_0, k_0, k_1, j_1 in T.grid(128, 16, 32, 4, 8):\n",
      "                with T.block(\"Y\"):\n",
      "                    vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                    vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
      "                    vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
      "                    T.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
      "                    T.writes(Y[vn, vi, vj])\n",
      "                    with T.init():\n",
      "                        Y[vn, vi, vj] = T.float32(0)\n",
      "                    Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
      "        for n, i, j in T.grid(16, 128, 128):\n",
      "            with T.block(\"C\"):\n",
      "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
      "                T.reads(Y[vn, vi, vj])\n",
      "                T.writes(C[vn, vi, vj])\n",
      "                C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
      "    \n",
      "\n",
      "tir.BlockRV(0x11e8f8d10)\n",
      "tir.LoopRV(0x11e8ef090)\n",
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
      "        for n in T.parallel(16):\n",
      "            for i, j_0 in T.grid(128, 16):\n",
      "                for k_0, k_1, j_1 in T.grid(32, 4, 8):\n",
      "                    with T.block(\"Y\"):\n",
      "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                        vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
      "                        vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
      "                        T.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
      "                        T.writes(Y[vn, vi, vj])\n",
      "                        with T.init():\n",
      "                            Y[vn, vi, vj] = T.float32(0)\n",
      "                        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
      "                for ax0 in T.serial(8):\n",
      "                    with T.block(\"C\"):\n",
      "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                        vj = T.axis.spatial(128, j_0 * 8 + ax0)\n",
      "                        T.reads(Y[vn, vi, vj])\n",
      "                        T.writes(C[vn, vi, vj])\n",
      "                        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
      "    \n",
      "\n",
      "# from tvm.script import tir as T\n",
      "@tvm.script.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
      "        # function attr dict\n",
      "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
      "        # body\n",
      "        # with T.block(\"root\")\n",
      "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
      "        for n in T.parallel(16):\n",
      "            for i, j_0 in T.grid(128, 16):\n",
      "                for j_1_init in T.serial(8):\n",
      "                    with T.block(\"Y_init\"):\n",
      "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                        vj = T.axis.spatial(128, j_0 * 8 + j_1_init)\n",
      "                        T.reads()\n",
      "                        T.writes(Y[vn, vi, vj])\n",
      "                        Y[vn, vi, vj] = T.float32(0)\n",
      "                for k_0, k_1, j_1 in T.grid(32, 4, 8):\n",
      "                    with T.block(\"Y_update\"):\n",
      "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                        vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
      "                        vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
      "                        T.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
      "                        T.writes(Y[vn, vi, vj])\n",
      "                        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
      "                for ax0 in T.serial(8):\n",
      "                    with T.block(\"C\"):\n",
      "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
      "                        vj = T.axis.spatial(128, j_0 * 8 + ax0)\n",
      "                        T.reads(Y[vn, vi, vj])\n",
      "                        T.writes(C[vn, vi, vj])\n",
      "                        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
      "    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># from tvm.script import tir as T</span>\n",
       "<span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">j_1_init</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_init&quot;</span><span class=\"p\">):</span>\n",
       "                        <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1_init</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">k_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">):</span>\n",
       "                    <span class=\"k\">for</span> <span class=\"n\">k_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
       "                        <span class=\"k\">for</span> <span class=\"n\">j_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_update&quot;</span><span class=\"p\">):</span>\n",
       "                                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                                <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1</span><span class=\"p\">)</span>\n",
       "                                <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">k_0</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">k_1</span><span class=\"p\">)</span>\n",
       "                                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">ax0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
       "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
       "                        <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">ax0</span><span class=\"p\">)</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} from tvm.script import tir as T}\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bmm\\PYZus{}relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{n} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{parallel}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{16}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{k}{for} \\PY{n}{j\\PYZus{}1\\PYZus{}init} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}init}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                        \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1\\PYZus{}init}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{k}{for} \\PY{n}{k\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{k}{for} \\PY{n}{k\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{unroll}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n",
       "                        \\PY{k}{for} \\PY{n}{j\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n",
       "                            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}update}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n",
       "                                \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1}\\PY{p}{)}\n",
       "                                \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{reduce}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{k\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{4} \\PY{o}{+} \\PY{n}{k\\PYZus{}1}\\PY{p}{)}\n",
       "                                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n",
       "                \\PY{k}{for} \\PY{n}{ax0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                        \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{ax0}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# from tvm.script import tir as T\n",
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
       "        for n in T.parallel(16):\n",
       "            for i, j_0 in T.grid(128, 16):\n",
       "                for j_1_init in T.vectorized(8):\n",
       "                    with T.block(\"Y_init\"):\n",
       "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
       "                        vj = T.axis.spatial(128, j_0 * 8 + j_1_init)\n",
       "                        T.reads()\n",
       "                        T.writes(Y[vn, vi, vj])\n",
       "                        Y[vn, vi, vj] = T.float32(0)\n",
       "                for k_0 in T.serial(32):\n",
       "                    for k_1 in T.unroll(4):\n",
       "                        for j_1 in T.serial(8):\n",
       "                            with T.block(\"Y_update\"):\n",
       "                                vn, vi = T.axis.remap(\"SS\", [n, i])\n",
       "                                vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
       "                                vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
       "                                T.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
       "                                T.writes(Y[vn, vi, vj])\n",
       "                                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
       "                for ax0 in T.vectorized(8):\n",
       "                    with T.block(\"C\"):\n",
       "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
       "                        vj = T.axis.spatial(128, j_0 * 8 + ax0)\n",
       "                        T.reads(Y[vn, vi, vj])\n",
       "                        T.writes(C[vn, vi, vj])\n",
       "                        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
       "    "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "# TODO: transformations\n",
    "# Hints: you can use\n",
    "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
    "# or `print(sch.mod.script())`\n",
    "# to show the current program at any time during the transformation.\n",
    "\n",
    "# Step 1. Get blocks\n",
    "block_Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
    "\n",
    "# Step 2. Get loops\n",
    "b, i, j, k = sch.get_loops(block_Y)\n",
    "\n",
    "# parallelize the outermost loop\n",
    "sch.parallel(b)\n",
    "\n",
    "# Organize the loops\n",
    "k0, k1 = sch.split(k, factors=[32, 4])\n",
    "j0, j1 = sch.split(j, factors=[16, 8])\n",
    "                  \n",
    "sch.reorder(j0, k0, k1, j1)\n",
    "print(sch.mod.script())\n",
    "\n",
    "# reverse compute\n",
    "block_C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
    "sch.reverse_compute_at(block_C, j0)\n",
    "print(sch.mod.script())\n",
    "\n",
    "# decompose reduction\n",
    "Y_init = sch.decompose_reduction(block_Y, k0)\n",
    "print(sch.mod.script())\n",
    "\n",
    "# vectorize /  unroll\n",
    "n, i, j_0, j_1_init = sch.get_loops(Y_init)\n",
    "sch.vectorize(j_1_init)\n",
    "n, i, j_0, i2_1 = sch.get_loops(block_C)\n",
    "sch.vectorize(i2_1)\n",
    "\n",
    "block_Y_update = sch.get_block(\"Y_update\", func_name=\"bmm_relu\")\n",
    "n, i, j_0, k_0, k_1, j_1 = sch.get_loops(block_Y_update)\n",
    "sch.unroll(k_1)\n",
    "\n",
    "# n, i, j_0, k_0, k_1, j_1 = sch.get_loops(block_Y_update)\n",
    "# sch.parallel(n)\n",
    "...\n",
    "\n",
    "IPython.display.Code(sch.mod.script(), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
    "print(\"Pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[20:47:14] /Users/yd/Documents/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "  42.2089      42.2089      42.2089      42.2089       0.0000   \n",
      "               \n",
      "After transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   1.8328       1.8328       1.8328       1.8328       0.0000   \n",
      "               \n"
     ]
    }
   ],
   "source": [
    "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
    "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
    "\n",
    "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "print(\"Before transformation:\")\n",
    "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
    "\n",
    "print(\"After transformation:\")\n",
    "print(f_timer(a_tvm, b_tvm, c_tvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1082c47d0cc768e78b2fafe6fb82031f0ef649fe2be17ed77a3652f892e34dd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
